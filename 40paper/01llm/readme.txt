https://github.com/calculon-ai/calculon


https://baoyu.io/translations/llm/reading-list-for-andrej-karpathys-intro-to-large-language-models-video  大语言模型



transformer，attention is all you need


要理解《Attention Is All You Need》这篇论文，你需要具备以下基础知识：

机器学习和深度学习：了解机器学习和深度学习的基本概念，包括神经网络、损失函数、优化算法等。

自然语言处理（NLP）：对自然语言处理领域的基本概念和任务有一定了解，例如文本分类、机器翻译、语言模型等。

神经网络：熟悉神经网络的基本结构和层级，如全连接层、卷积神经网络（CNN）和循环神经网络（RNN）。

Transformer 模型：熟悉Transformer模型的基本架构和关键组件，如自注意力机制、位置编码、编码器和解码器等。

注意力机制：了解注意力机制的基本原理和应用，包括自注意力和多头注意力。

数学和线性代数：具备基本的数学和线性代数知识，包括向量、矩阵运算、矩阵乘法、矩阵求逆等。

编程和深度学习框架：熟悉编程和至少一种常用的深度学习框架，如Python和TensorFlow、PyTorch等。

这些基础知识将帮助你更好地理解《Attention Is All You Need》论文中描述的模型架构和算法原理。如果你在某些领域有较少的经验，可以通过阅读相关教材、教程或参加在线课程来加强你的基础知识。

