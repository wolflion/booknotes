## 《存储技术原理分析》

### chap5、块I/O子系统

#### 5.1、概述

+ 块I/O子系统，在**SCSI子系统**上层，**文件系统层**下面，分为三个部分

  + 通用块层（block_device，gendisk），接上层发出的磁盘请求，并最终发出I/O请求。
  + I/O调度层（noop，deadline，cfq），收到请求后，会试图合并一些请求，并根据设置好的调度算法，回调驱动层提供的请求处理函数。
  + 块设备驱动层（md驱动、Device Mapper驱动），对于大多数逻辑块设备，并不需要和硬件打交道，**对于SCSI块设备**才与SCSI子系统联系起来。

  + **与SISI子系统**共用**磁盘驱动（sd）**

+ 块I/O子系统的一般的I/O处理流程是：

  + 上层调用通用块层提供的接口向I/O子系统提交I/O请求，放到I/O调度层调度队列，各种处理后派发到具体块设备的等待队列，由后者的驱动进一步处理。
  + 两种形式的I/O请求：
    + 通用块层的I/O请求，`bio结构`
    + 块设备驱动层的I/O请求，要调度层转换一下，`request描述`

+ **聚散I/O（scatter/gather I/O）**机制：将对磁盘上连续，但内存中不连续的数据访问由单次操作即可完成。

  + 在单次操作中，从磁盘的连续扇区中的数据读取到几个物理上不连续

+ 块I/O子系统的代码主要在block目录，主要功能是：
  + 在内存中构建通用磁盘、分区和块设备之间的关系
  + 向上层提供I/O请求API，并实现I/O调试，并请求派发到具体块设备的请求队列执行
  + 提供请求完成的下半部处理API，直至最终调用上层的请求完成回调函数结束I/O

#### 5.2、块I/O子系统对象

##### 5.2.1、gendisk：通用磁盘

##### 5.2.2、hd_struct：分区

##### 5.2.3、block_device：块设备

##### 5.2.4、request_queue：请求队列

##### 5.2.5、request：块设备驱动层请求

##### 5.2.6、bio：通用块层请求【include/linux/bio.h】

#### 5.3、添加磁盘到系统

##### 5.3.1、分配通用磁盘操作符

+ block/genhd.c中`alloc_disk()`->`alloc_disk_node()`
+ block/genhd.c中`add_disk()`

##### 5.3.2、添加到sysfs文件系统

+ fs/partitions/check.c中的`add_disk()`->`register_disk()`

##### 5.3.3、获取磁盘块设备描述符

+ block/genhd.c中的`add_disk()`->`register_disk()`->`bdget_disk()`
+ fs/block_dev.c中的`sd_poobe()`->`add_disk()`->`register_disk()`->`bdget_disk()`->`bdget()`

##### 5.3.4、打开磁盘块设备描述符

+ fs/block_dev.c中的`add_disk()`->`register_disk()`->`blkdev_get()`->`_blkdev_get()`

##### 5.3.5、重新扫描磁盘分区

+ 中的`add_disk()`->`register_disk()`->`blkdev_get()`->`_blkdev_get()`->`rescan_partitions()`

##### 5.3.6、设备号映射机制

#### 5.4、请求处理过程

##### 5.4.1、上层向块I/O子系统提交请求

##### 5.4.2、构造、排序或合并请求

##### 5.4.3、scsi策略例程逐个处理请求

##### 5.4.4、为请求构造scsi命令

##### 5.4.5、为scsi命令准备聚散列表

##### 5.4.6、派发sisi命令到低层驱动

#### 5.5、I/O调度算法

##### 5.5.1、为请求队列建立关联的I/O调度队列

##### 5.5.2、判断bio是否可以被合并到request

##### 5.5.3、将请求添加到I/O调度队列或请求队列

##### 5.5.4、从I/O调度队列派发请求到请求队列

#### 5.6、请求处理完成

##### 5.6.1、低层驱动调用完成回调函数

##### 5.6.2、引发块I/O子系统的软中断

##### 5.6.3、调用请求队列的软中断回调

##### 5.6.4、调用上层的完成回调函数

#### 5.7、屏障I/O（barrier）处理

+ Linux 2.6引入
+ 屏障I/O有2个目的：**排序和冲刷**

##### 5.7.1、屏障I/O接口

+ block/blk-barrier.c中的`sd_probe()`->`sd_probe_async()`->`sd_revalidate_disk()`->`blk_queue_ordered()`

##### 5.7.2、添加屏障请求

+ block/elevator.c中的

##### 5.7.3、处理屏障请求

+ block/blk_barrier.c中的`submit_bio()`->`generic_make_request()`->...->`blk_peek_request()`->`__elv_next_request()`->`blk_do_ordered()`
+ *lionel，函数未写完*

##### 5.7.4、完成屏障请求

+ block/elevator.c
+ block/blk_barrier.c

#### 5.8、完整性保护

##### 5.8.1、数据完整性对象

##### 5.8.2、为块设备注册完整性能力

##### 5.8.3、为bio准备完整性元数据

##### 5.8.4、校验完整性元数据

##### 5.8.5、修正bio基准标签

#### 5.9、磁盘类设备驱动编程模式

### chap8、文件系统

#### 8.1、概述

+ VFS在系统启动时建立，在系统关闭时消亡。
+ Minix为例
  + 文件系统开头，**通常为一个扇区**，存入引导程序
  + 超级块，存储磁盘设备上文件系统结构的信息，并说明各部分的大小
  + i节点位图：描述磁盘上每个i节点的使用情况。除了位0，i节点位图中每个比特位依次代表盘上i节点区中的一个i节点。
  + 逻辑块位图：磁盘上每个逻辑块的使用情况。除了位0，其它位依次表示盘上逻辑块区中的一个逻辑块。
  + i节点：反映的是**文件的元数据**
  + 逻辑块编号：**保存文件的数据**。每个文件有且仅有一个i节点，但可以有0，1或多个逻辑块
+ 文件系统类型、超级块、inode、dentry和vfsmount
+ 每个文件系统装载实例有四个必备元素：**vfsmount、超级块、根inode和根dentry**。
+ 一个文件系统类型可以有多个超级块实例、每个超级块实例又可以有多个装载实例。*把某个分区，格式化为某个具体的文件系统类型*

#### 8.2、文件系统对象

##### 8.2.1、file_system_type：文件系统类型

+ fs/filesystem.c中register_filesystem()
+ include/linux/fs.h中的`struct file_system_type{};`
+ fs/filesystems.c
+ 文件系统类型注册的主要目的是**向Linux VFS提供get_sb和kill_sb回调函数**，在Linux装载或卸载时被调用。
	+ get_sb回调函数实现中调用`get_sb_bdev`
	+ kill_sb回调函数则直接实例化为`kill_block_super`
+ 文件系统类型将所有超级块实例组装成一个链表，**链表的表头为fs_supers**。超级块对象通过`s_instances`链接到所属文件系统类型的超级块实例链表中。

##### 8.2.2、super_block：vfs超级块

+ include/linux/fs.h中的`struct super_block{};`

##### 8.2.3、inode：vfs索引节点

+ include/linux/fs.h中的`struct inode{};`
+ 以ext2为例，`struct ext2_inode_info{};`
+ **inode包含了文件系统各种对象的元数据**。
+ 具体的文件系统，有两种形式的inode，一种是内存inode，另一种是磁盘inode。
+ **所有inode加入到全局哈希表inode_hashtable中**
+ inode可以表示多种对象，包含**目录、文件、符号链接、字符设备、块设备**等

##### 8.2.4、dentry：vfs目录项

+ **inode反映的是文件系统对象的元数据，而dentry则表示文件系统对象在文件系统树中的位置**。dentry和inode是多对一的关系，每个dentry只有一个inode，由d_inode指向；而一个inode可能对应多个dentry（例如硬链接），它将这些dentry组成以i_dentry的链表，每个dentry通过d_alias加入所属inode的i_dentry链表中。
+ include/linux/dcache.h中`struct dentry{};`

##### 8.2.5、vfsmount：文件系统装载

+ include/linux/mount.h中的`struct vfsmount{};`
+ vfsmount对象反映了一个已装载的文件系统实例。
+ **跟dentry一样，可以为vfsmount定义父子关系**
+ **除了根vfsmount以外，所有vfsmount加入到一个mount_hashtable全局哈希表中**，哈希项的索引计算基于父vfsmount描述符的地址以及它在父文件系统中的装载点dentry描述符的地址。
+ 现在文件系统的位置需要由`<vfsmount, dentry>`二元组来定。

#### 8.3、装载文件系统

+ 装载的4个要素：**vfsmount、super_block、根dentry、根inode**。
+ 【这个地方有人家的学习记录：https://blog.csdn.net/jinking01/article/details/105090539】
  【https://blog.csdn.net/u012489236/article/details/124523247】*这个系列也看一下*

##### 0、

+ `mount -t FILE_SYSTEM_TYPE_B /dev/sda3  /mnt/d/project/`

##### 8.3.1、mount系统调用的处理流程

+ fs/namespace.c中的`sys_mount()`
+ `sys_mount()`->`do_mount()`->`do_new_mount()`
+ 新建装载的实例
  + 构造子文件系统的装载实例。 `do_kern_mount`
  + 将子文件系统的装载实例“挂钩到”父文件系统的装载点。 `do_add_mount`

##### 8.3.2、构建子文件系统装载实例

+ `sys_mount()`->`do_mount()`->`do_new_mount()`->`do_kern_mount()`
+ `sys_mount()`->`do_mount()`->`do_new_mount()`->`do_kern_mount()`->`vfs_kern_mount()`
+ **构建文件系统装载实例**，即构建vfsmount，super_block，根dentry和根inode之间的关系。
+ do_kern_mount（fs/super.c）
+ **vfs_kern_mount函数被交付的任务是构建文件系统装载实例，即构建vfsmount、super_block、根dentry和根inode之间的关系**。
+ **vfsmount是一个纯内存中的元素**。

##### 8.3.3、 关联文件系统的超级块实例

+ `sys_mount()`->`do_mount()`->`do_new_mount()`->`do_kern_mount()`->`vfs_kern_mount()`->`minix_get_sb()`->`get_sb_bdev()`
+ 3种get_sb的实现

##### 8.3.4、调用回调函数填充超级块

+ `sys_mount()`->`do_mount()`->`do_new_mount()`->`do_kern_mount()`->`vfs_kern_mount()`->`minix_get_sb()`->`get_sb_bdev()`->`minx_fill_super()`

##### 8.3.5、装载到全局文件系统树

+ `sys_mount()`->`do_mount()`->`do_new_mount()`->`do_add_mount()`【fs/namespace.c中】

#### 8.4、路径查找

+ 用户空间表示文件使用的是路径名字符串，内核中对文件的操作需要依据**超级块、inode、dentry以及vfsmount等**。
+ include/linux/path.h
+ 某个目录下查找给定名字的文件，有三个动作：

  + 1、读出目录的内容，找到该文件对应的项，获得其i节点编号
  + 2、从i节点表中找到该编号的inode，它直接或间接指向包含文件数据的逻辑块
  + 3、读取这些逻辑块即能获得该文件的内容
+ include/linux/namei.h中的`struct nameidata{};`

+ 路径名字符串由反斜杠“/”分隔的多个部分组成，每一部分称为**分量（Component）**
+ **路径查找的过程就是分量解析的过程**，根据路径名层次，从第一个分量开始，一层一层推进，直到最后一个分量或者失败。
+ **路径查找还需要考虑符号链接**
+ **路径查找上下文**

##### 8.4.1、路径查找入口

+ fs/namei.c中的`path_lookup()`

  + *2.6.18代码还是有点的*
+ 在不同的条件下调用的用于路径名查找的函数
  + path_lookup
  	+ `path_lookup()->do_path_lookup()->path_walk()->link_path_walk()`
  + kern_path
  + user_path_at

##### 8.4.2、逐个分量解析

+ `link_path_walk()`，**重点**
+ include/linux/dcache.c 中的`qstr`结构

##### 8.4.3、解析单个分量

+ `do_lookup()`

+ `path_lookup()->do_path_lookup()->path_walk()->link_path_walk()->do_lookup()`
+ **do_lookup()真正执行单个分量的查找**

##### 8.4.4、上溯通过装载点

+ `follow_dotdot()`

+ `path_lookup()->do_path_lookup()->path_walk()->link_path_walk()->follow_dotdot()`

##### 8.4.5、下溯通过装载点

+ `follow_mount()`

+ `path_lookup()->do_path_lookup()->path_walk()->link_path_walk()->follow_dotdot()->follow_mount()`
+ `follow_mount()`和`_follow_mount()`功能相同，参数不同

##### 8.4.6、处理符号链接

+ `do_follow_link()`
+ 符号链接有两种实现方式：
  + 一种方式（Slow Symlink）：将符号链接信息保存在标准的磁盘块，如同常规文件一样。
  + 另一种方式（Fast Symlink）：将链接文本串保存在inode中。
+ `path_lookup()->do_path_lookup()->path_walk()->link_path_walk()->do_follow_link()->_do_follow_link()->_vfs_follow_link()`
+ 为了避免恶意用户设置大量的符合链接，**Linux内核对符号链接的总数也进行限制**。

#### 8.5、打开文件

+ 将路径名转换为**内核中唯一定位的`<vfsmount,dentry>`二元组**

+ 文件描述符，**指的是file结构的对象**

+ 每个进程可以打开多个文件，将它们组织成打开文件表的形式，实际上是指向文件描述符的指针数组，**数组索引即为文件句柄**。

+ 打开文件表在内核中对应fdtable结构中，include/linux/fdtable.h中的`struct fdtable{};`

+ include/linux/fs.h中的`struct file{};`

+ include/linux/fdtable.h中的`struct files_struct{};`

##### 8.5.1、open系统调用的处理流程

+ 分配一个文件描述符，正确设置`f_mapping（文件地址空间）`和`f_op（文件操作表）`，在打开文件表中找到一个用于保存它的文件句柄。
+ sys_open()->do_sys_open()->do_filp_open()->do_last()->namidata_to_filp()->`__dentry_open()`，lionel，这个要花时间去串一下代码注释，2月17日晚上逐行读一下
+ `sys_open()->do_sys_open()->do_filp_open()`

##### 8.5.2、

+ `sys_open()->do_sys_open()->do_filp_open()->do_last()`

##### 8.5.3、

+ `sys_open()->do_sys_open()->do_filp_open()->do_last()->namidata_to_filp()->__dentry_open()`
+ 各种文件打开时的关键处理，
	+ 1、常规文件
	+ 2、字符设备文件
		+ inode的文件操作表指向def_char_fops，它只定义了open回调函数，并且被实例化为`chrdev_open`
	+ 3、块设备文件
		+ inode的文件操作表指向def_blk_fops，对应的open回调函数是`blkdev_open`

#### 8.6、读文件（重点）

+ **地址空间（Address Space）** 的引入，将对象在磁盘中（可能不连续的）数据以及页面为单位连续地呈现出来。

+ include/linux/fs.h中的`struct address_space{};`

+ 地址空间的属主对象被定义为属主对象的inode。**对于常规文件或目录文件，这就是文件对应的inode描述符**。

+ radix树，**树的根节点为地址空间的page_tree域**，文件inode地址空间保存的是数据块。

+ **VFS通过调用write_begin通知具体文件系统，准备写文件的字节begin~end到给定的页面**。

+ include/linux/mm_types.h中的`struct page{};`

##### 8.6.1、

+ sys_read()->vfs_read()->do_sync_read()->generic_file_aio_read()->do_generic_file_read() 【mm/filemap.c】

##### 8.6.2、基于缓冲页面构造I/O请求

+ **缓冲页面**：是指将页面划分为一个个的缓冲块（Buffer Block），以缓冲块为单位进行I/O。
+ 管理缓冲块的数据结构为`buffer_head`，被称作**缓冲头**
+ I/O的基本单位已经换成bio，而buffer_head仅被用来提取块映射（通过get_block_t调用），用于跟踪页面的状态（通过page_mapping），以及用于封装bio提交以向后兼容（例如submit_bh）
+ *706/792，把书中的内容提了一下*，lionel，把之前的疑惑
+ + `sys_read()->vfs_read()->do_sync_read()->generic_file_aio_read()->do_generic_file_read()->block_read_full_page()->submit_bh()`

##### 8.6.3、直接针对页面构造I/O请求

+ Linux为基于磁盘的文件系统提供另一种策略，构造尽可能大的bio向下层提交。对应的函数为`mpage_readpage()`，实际上ext3文件系统readpage方法实现为`ext3_readpage()`【fs/ext3/inode.c】就是直接调用mpage_readpage函数
+ `sys_read()->vfs_read()->do_sync_read()->generic_file_aio_read()->do_generic_file_read()->mpage_read()->do_mpage_readpage()`
+ 图8-24，一个页面的逻辑块映射到磁盘块的6种情况
	+ 第一种：
	+ 第六种：页面的所有逻辑块都未被映射到磁盘上，这时会跳过这个页面的处理。

##### 8.6.4、

+ `sys_read()->vfs_read()->do_sync_read()->generic_file_aio_read()->do_generic_file_read()->block_read_full_page()->minix_get_block()->get_block()`

#### 8.7、写文件

##### 8.7.1、write系统调用的处理流程

+ `sys_write()->generic_file_aio_write()->__generic_file_aio_write()->generic_file_buffered_write()->generic_perform_write()`

##### 8.7.2、通知为缓冲写请求作准备

+ `sys_write()->generic_file_aio_write()->__generic_file_aio_write()->generic_file_buffered_write()->generic_perform_write()->__minix_write_begin()->block_write_begin()->__block_prepare_write()`

##### 8.7.3、通知数据已复制到缓冲区

+ `sys_write()->generic_file_aio_write()->__generic_file_aio_write()->generic_file_buffered_write()->generic_perform_write()->generic_write_end()->block_write_end()->__block_commit_write()`

#### 8.8、冲刷文件

##### 8.8.1、BDI相关对象

+ **BDI（Backing Device Information）**
+ 1、后备设备信息：backing_dev_info
+ 2、BDI回写线程：bdi_writeback
+ 3、BDI回写任务：bdi_work

  ##### 8.8.2、注册后备设备信息
+ `bdi_register()`

  ##### 8.8.3、forker线程执行流程
+ **forker线程的作用是孵化flusher线程**，当前只有一个BDI能支持forker线程，就是**default_backing_dev_info**。
+ `bdi_forker_task()`

  ##### 8.8.4、flusher线程执行流程
+ `bdi_start_fn()`
+ 2、冲刷单个inode
+ 3、以缓冲I/O写页面
	
	+ fs/buffer.c中的`block_write_full_page_endio()`
+ 4、缓冲I/O完成回调
	+ fs/buffer.c中的`end_buffer_async_write()`

	  ##### 8.8.5、同步相关系统调用
+ 1、fsync和fdatasync
+ 2、sync

#### 8.9、块设备文件

##### 8.9.1、块设备的主inode和次inode

+ 1、宿主文件系统的块设备文件inode
+ 2、bdev文件系统的块设备inode
	+ `sys_open()->do_sys_open()->do_filp_open()->do_last()->nameidata_to_filp()->__dentry_oepn()->blkdev_open()->bd_acquire()`
+ 3、主inode与次inode的关联

##### 8.9.2、对块设备文件的操作转换为对块设备的操作

##### 8.9.3、对块设备文件的读/写作用于块设备之上

#### 8.10、文件系统编程模式

+ 实施步骤如下：
  + 1、定义超级块结构
  + 2、定义inode结构
  + 3、实现各种类型文件的inode操作表
  + 4、实现各种类型文件的file操作表
  + 5、实现各种类型文件的address_space操作表
  + 6、实现超级块操作表
  + 7、实现dentry操作表
  + 8、定义文件系统类型
  + 9、模块加载和卸载方法

