<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Calculon大语言模型的方法和工具 - lionel的技术笔记</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Calculon\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u548c\u5de5\u5177";
        var mkdocs_page_input_path = "40paper\\01llm\\Calculon\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u548c\u5de5\u5177.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> lionel的技术笔记
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">简介</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01daily/">daily</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../02ds/">ds</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../03cpp/">cpp</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../21tool/">tool</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">C++</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../20C%2B%2B/effectiveC%2B%2B/">《Effective C++》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../20C%2B%2B/%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2C%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/">《深度探索C++对象模型》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../21STL/EffectiveSTL/">《Effective STL》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../21STL/C%2B%2B%E6%B3%9B%E5%9E%8BSTL%E5%8E%9F%E7%90%86%E5%92%8C%E5%BA%94%E7%94%A8/">《C++泛型STL原理和应用》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../21STL/STL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/">《STL源码剖析》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../22C%2B%2Bmodern/%E6%B7%B1%E5%85%A5%E5%BA%94%E7%94%A8C%2B%2B11/">《深入应用C++11》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">基础知识</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%BC%E8%AE%BA/">《操作系统导论》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">《大话设计模式》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90_C%2B%2B4th/">《数据结构与算法分析_C++4th》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E7%AE%97%E6%B3%95%284th%29/">《算法4th》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90-%E5%BC%A0%E5%86%9B/">《算法设计与分析-张军》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E5%A4%A9%E8%A1%8C-%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/">《天行-算法设计与实现》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%95%99%E7%A8%8B-%E6%9D%8E%E6%98%A5%E8%91%86/">《数据结构教程》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../408/%E6%96%B0%E7%BC%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%A0%E9%A2%98%E4%B8%8E%E8%A7%A3%E6%9E%90/">《新编数据结构习题与解析》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">网络编程</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../10network/TCPIP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">《TCP/IP网络编程》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../10network/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/">《Linux高性能服务器编程》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../10network/TCPIP%E8%AF%A6%E8%A7%A3%E5%8D%B71/">《TCPIP详解卷1》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../10network/Linux%E5%86%85%E6%A0%B8%E7%BD%91%E7%BB%9C%E6%A0%88%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90/">《Linux内核网络栈源代码情景分析》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../10network/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E7%BD%91%E7%BB%9C/">《深入理解Linux网络》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">机器&深度学习</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../30machineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/">《机器学习线性代数基础》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../31deepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0/">《深度学习入门：基于Python的理论与实现》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">文件系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../11filesystem/Linux%E5%86%85%E6%A0%B8%E6%8E%A2%E7%A7%98/">《Linux内核探秘》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../11filesystem/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95/">《文件系统技术内幕》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../11filesystem/%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/">《存储技术原理分析》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">存储</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../12storage/ceph%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/">《ceph设计原理与实现》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">视频</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../14video/FFmpeg%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/">《FFmpeg入门到精通》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../14video/WebRTC%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/">《WebRTC权威指南》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../14video/WebRTC%E9%9F%B3%E8%A7%86%E9%A2%91%E5%AE%9E%E6%97%B6%E4%BA%92%E5%8A%A8%E6%8A%80%E6%9C%AF/">《WebRTC音视频实时互动技术》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../14video/%E6%96%B0%E4%B8%80%E4%BB%A3%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%A0%81%E6%A0%87%E5%87%86-H.264_AVC/">《新一代视频压缩码标准-H.264_AVC》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">内核</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../13kernel/Linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/">《Linux内核设计与实现》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../13kernel/%E6%B7%B1%E5%85%A5Linux%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E5%86%85%E6%A0%B8%E6%9C%BA%E5%88%B6/">《深入Linux设备驱动程序内核机制》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../13kernel/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">《深入理解Linux虚拟内存管理》</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../13kernel/深入理解Linux网络技术内幕.md">《深入理解Linux网络技术内幕》</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../13kernel/Linux内核源代码剖析-tcpip实现.md">《Linux内核源代码剖析-TCP/IP实现》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../13kernel/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Linux%E5%86%85%E6%A0%B8/">《深入理解Linux内核》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">工具</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../15tool/Wireshark%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/">《Wireshark网络分析实战》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../15tool/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Eshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%A4%A7%E5%85%A8%283rd%29/">《Linux命令行与shell脚本编程大全(3rd)》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../15tool/python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%883rd%EF%BC%89/">《python程序设计（3rd）》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../15tool/python/Python%E7%BC%96%E7%A8%8B%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/">《Python编程从入门到实践》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">刷题</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../91leetcode/%E5%89%91%E6%8C%87offer2nd/">《剑指offer2nd》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../91leetcode/%E5%89%91%E6%8C%87offer%E4%B8%93%E9%A1%B9%E7%AA%81%E7%A0%B4/">《剑指offer专项突破》</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../96output/OD基础题.md">OD基础题</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../96output/OD进阶题.md">OD进阶题</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">网课</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../90lecture/01Linux%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/">《Linux高并发网络编程开发》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../90lecture/%E4%BE%AF%E6%8D%B7/%E4%BE%AF%E6%8D%B7C%2B%2B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%8660%E8%AE%B2/">《侯捷C++内存管理60讲》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../90lecture/11NJU%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/">《NJU算法设计与分析》</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">英语专</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../60English/00794%E7%BB%BC%E5%90%88%E8%8B%B1%E8%AF%AD%E4%B8%80%E4%B8%8A/">《综合英语(一)上》</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../95selfStudy/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">《概率率与数理统计》</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">lionel的技术笔记</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Calculon大语言模型的方法和工具</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="calculon">《Calculon：大语言模型的方法和工具》<a class="headerlink" href="#calculon" title="Permanent link">&para;</a></h2>
<h3 id="paper">Paper<a class="headerlink" href="#paper" title="Permanent link">&para;</a></h3>
<ul>
<li>https://dl.acm.org/doi/pdf/10.1145/3581784.3607102</li>
</ul>
<h4 id="abstract">ABSTRACT<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h4>
<p>This paper presents a parameterized analytical performance model of transformer-based Large Language Models (LLMs) for guiding high-level algorithm-architecture codesign studies.</p>
<ul>
<li>这篇论文展示了 基于transformer的LLMs 参数分析性能模型，为指导高级别算法架构codesign研究</li>
</ul>
<p>This model de-rives from an extensive survey of performance optimizations that have been proposed for the training and inference of LLMs; the model’s parameters capture application characteristics, the hard-ware system, and the space of implementation strategies.</p>
<ul>
<li>这个模型性能优化的可执行调查，展示了LLMs的训练和推理目的；模型的参数捕捉应用字符，硬件系统，实现策略的空间。</li>
</ul>
<p>With such a model, we can systematically explore a joint space of hardware and software configurations to identify optimal system designs un-der given constraints, like the total amount of system memory.</p>
<ul>
<li>在这个模型中，我们系统和探索了硬件和软件的联合空间，去标识优化的系统设计在给定的限制中，像大量的系统内存。</li>
</ul>
<p>We implemented this model and methodology in a Python-based open-source tool called Calculon.</p>
<ul>
<li>我们实现了这个模型基于开源的python，叫Calculon</li>
</ul>
<p>Using it, we identified novel system designs that look significantly different from current inference and training systems, showing quantitatively the estimated potential to achieve higher efficiency, lower cost, and better scalability.</p>
<ul>
<li>使用它，我们标识文本系统设计 与众不同的当前的推理和训练系统，展现质量，估计潜在达到高效，低成本和更好的规模</li>
</ul>
<h4 id="1introduction">1、INTRODUCTION<a class="headerlink" href="#1introduction" title="Permanent link">&para;</a></h4>
<p>We consider the task of conducting high-level analyses for algorithm-architecture codesign of distributed clusters and transformer-based Large Language Models (LLMs) [3, 4, 36, 39, 40].</p>
<ul>
<li>我们认为</li>
</ul>
<p>By “high level,” we mean focusing on developing and using fast and coarse-grained analytical or semi-empirical models of the software and hardware, a stage of design that precedes detailed simulation or implemen-tation on actual hardware. </p>
<p>The goal is to estimate the best-case
relative improvements that might come from significant changes
to the system or software, as well as combinations of system and</p>
<p>software configurations that might be unusual or otherwise costly
and difficult to implement. Since high level models are expected to
be much cheaper than detailed simulation, they should facilitate
rapid exploration of a potentially large parameter space during the
early phases of codesign.
In this work, our starting point is Megatron, a large family of
open-source LLM instances developed by NVIDIA [44]. The cost
of training such models is high: a version of Megatron having
one trillion (1T) parameters was recently trained over 84 days on
450 billion tokens using 3,072 NVIDIA A100 Graphics Processing
Unit (GPU) and executing more than 1,000 zettaFLOP (1 × 1021
floating-point operations) [29, 30]. This cost roughly equals seven
hundred years on a single GPU and over six million dollars (US)
assuming a single GPU at $1 per hour cloud-GPU rates. Incurring
such costs is commonplace; the PaLM-540B model recently trained
by Google used 2,572 zettaFLOP with similar numbers of Tensor
Processing Units (TPUs) and more than 8 million TPU hours [6].
Such high costs strongly motivate any combination of algorithmic,
software, or hardware redesign that can reduce them.
Consequently, there are proposed enhancements in algorithms
and software [29, 37, 38] and options for hardware acceleration [18,
31]. However, selecting a good configuration in practice has relied
primarily on heuristic reasoning [29]. While these proposals have
yielded impressive results, it has also been observed that distributed
training runs at a FLOP/s rate well below 50% of peak despite the
prevalence of matrix multiply (GEMM) operations [34].
The challenge is that the codesign landscape is quite large, mak-
ing it hard to reason about the impact of major changes to arbi-
trary combinations of hardware and software. For example, con-
sider that limited GPU memory capacity requires dividing a large
model among processors. Doing so can be achieved via model paral-
lelism, which combines two strategies known as tensor parallelism
and pipeline parallelism [29]. However, when using NVIDIA A100
GPUs, the size of the NVLink domain is 8, which can limit tensor
parallelism performance [32]. To compensate, one can increase the
degree of pipeline parallelism—but that may in turn produce other
inefficiencies such as reduced utilization due to pipeline bubbles
and needing to recompute intermediate features in light of memory
constraints [13, 29]. Alternatively, one might improve the computer
network to support larger tensor parallelism domains; companies
and researchers have indeed considered doing so [17, 32]. However,
if memory capacity is the root issue, then a more cost-effective</p>
<p>strategy is to increase capacity. Overall, this example shows that
codesign should carefully consider and delicately balance memory
capacity, memory bandwidth, processing throughput (i.e., FLOP/s),
network bandwidth, and network scalability, all of which interact
with choices made in software. Therefore, to reason about these
trade-offs we seek a principled analysis framework that can be
extended or adapted in a hardware and software landscape under-
going rapid and continual evolution.
We propose one such model-driven approach for high-level code-
sign of LLM training and inference systems. We first identify a
parameterized space of possible configurations that span major
system features and common algorithmic and software implemen-
tation strategies (Section 2). We then develop a unified analytical
model to estimate the end-to-end performance of LLM training as
a function of the configuration parameters. This model allows us to
pose, mathematically, a constrained optimization problem: find the
configuration that yields the best performance given fixed system
constraints such as memory capacity and system or network size.
We encode this performance model and model-optimizer in a
tool called Calculon. The parameter space includes the structure
and number of weights in the LLM model, the implementation
strategy, and a schematic description of the hardware system (Ta-
ble 1). Since Calculon’s model is analytical, it can calculate and
return a complete breakdown of projected training or inference
time quickly, typically in much less than a 1 ms per configuration.
It thus becomes possible to search an entire configuration space
having many millions of combinations in only a few minutes on a
standard desktop computer.
This paper includes several analyses we have conducted using
Calculon. The modeling formulae themselves are complex to write
out in full; therefore, to save space, we focus on the analyses as
“proof-of-concept,” with detailed formulas appearing in Calculon’s
open-source repository, where our formulas and assumptions ap-
pear in full, allowing replication of our results or modification of our
assumptions.1 The analyses showcase Calculon’s potential to facili-
tate high-level codesign, revealing several system and optimization
insights that may contradict conventional wisdom:
(1) None of the existing software-parallelism strategies is uniformly
the “best.” However, there is an optimal split-parallelism strat-
egy that balances system resources well, with the exact optimum
depending on system parameters, as we show.
(2) The speed of LLM training can be a sensitive function of system
size, with performance variability (ratio of highest to lowest
performer) exceeding 6×. These “efficiency cliffs” come from</p>
<p>difficulties mapping LLM structures to a given number of pro-
cessors when sizes do not “divide evenly.”
(3) Adding a second high-capacity tier of memory for tensor of-
floading reduces performance variability across various LLM
configurations and sizes, enabling efficient training of larger
models. Moreover, the bandwidth requirement for efficient of-
floading is within current technological capabilities.
While these findings are estimates, they suggest quantitatively what
performance improvements are possible, a critical first step for LLM
codesign. Our methodology is systematic and rigorous, enabling
future exploration via more detailed experiments and simulation.</p>
<h4 id="2analytical-model">2、ANALYTICAL MODEL<a class="headerlink" href="#2analytical-model" title="Permanent link">&para;</a></h4>
<h5 id="21llm-configuration">2.1、LLM Configuration<a class="headerlink" href="#21llm-configuration" title="Permanent link">&para;</a></h5>
<ul>
<li>采用Megatron，the framework of Megatron [44] for describing the structure of transformer-based [49] LLMs。</li>
<li><strong>同步小批量随机梯度下降</strong>，<strong>Adam优化器</strong>，进行权重更新</li>
<li>每个Transformer块具有相同的结构，由一个多头注意力块后跟一个多层感知器（MLP）块组成<ul>
<li>hidden，隐藏大小</li>
<li>attn，the number of attention heads，注意力头数</li>
<li>the sequence size (seq)</li>
<li>training batch size (batch)</li>
<li>micro-batch size (m)</li>
<li>the number of transformer blocks (blocks)</li>
<li><em>问题是，典型的LLM，transformer块结构是啥？</em></li>
</ul>
</li>
</ul>
<h5 id="22hardware-configuration">2.2、Hardware Configuration<a class="headerlink" href="#22hardware-configuration" title="Permanent link">&para;</a></h5>
<ul>
<li>内存</li>
<li>计算</li>
<li>网络</li>
</ul>
<h5 id="23execution-configuration">2.3、Execution Configuration<a class="headerlink" href="#23execution-configuration" title="Permanent link">&para;</a></h5>
<ul>
<li>TP</li>
<li>PP</li>
<li>DP</li>
</ul>
<p>2.4 Performance Calculation</p>
<p>2.5 Validation</p>
<h3 id="code"><a href="https://github.com/calculon-ai/calculon">Code</a><a class="headerlink" href="#code" title="Permanent link">&para;</a></h3>
<ul>
<li>整体思路是<strong>先看整体架构，分成几个部分，各个部分是干啥的</strong>，然后具体的几个部分再<strong>通过单步调试的方式</strong>去理解细节</li>
</ul>
<h4 id="_1">入口<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>bin/calculon</p>
<ul>
<li><code>__main__</code></li>
<li>引入了<strong>argparse</strong>库，<em>干啥的不清楚，lionel</em></li>
<li>line44行是个啥？<ul>
<li>根据不同的version、runner、parameter去调用command_line中的<strong>create_parser</strong></li>
</ul>
</li>
</ul>
<pre class="highlight"><code class="language-python">  # Registers each command line interface.
  for cls in calculon.CommandLine.command_lines():
    cls.create_parser(sp)</code></pre>
<ul>
<li><em>要单点看一下，lionel</em></li>
</ul>
</li>
</ul>
<ul>
<li>
<p><code>__init__.py</code>怎么被加载的？lionel？</p>
<ul>
<li><code>from .runner import Runner</code>，表示从runner.py文件中导入Runner类<ul>
<li>runner是模块的文件名</li>
<li>Runner是该模块中定义的类名</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>
<p>command_line.py中的定义的抽象类，都没实现，都是其它继承类实现的</p>
<ul>
<li><strong>只实现了register</strong></li>
<li>子类的最后一行都有<code>calculon.CommandLine.register(Version)</code>是啥意思？<em>啥时候执行呢，猜测其是注册，但何时注册呢</em></li>
<li><strong>可能是个装饰器模式</strong></li>
<li><code>@staticmethod</code>是python中的装饰器，用于声明一个静态方法</li>
</ul>
</li>
</ul>
<h4 id="_2">总体分几步<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<ul>
<li>llm/runner.py中约定好了，但怎么调用的呢？<ul>
<li><code>class Runner(calculon.CommandLine):</code>，<strong>表示类Runner，继承calculon.CommandLine类</strong></li>
<li><code>calculon.CommandLine.register(Runner)</code>，每次都调用它们注册<ul>
<li>原型是<code>def register(cls):</code>，<em>其cls是啥意思，其实无所谓吗？lionel</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="_3">第一步<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme_extra.js" defer></script>
    <script src="../../../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
