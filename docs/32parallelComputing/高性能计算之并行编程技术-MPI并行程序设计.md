## 《高性能计算之并行编程技术-MPI并行程序设计》

### 0

+ part1（1-3）
+ part2（4-11）
+ part3、高级MPI（12-18）
+ part4、最新MPI（19-21）

### chap1、并行计算机（19/348）

#### 1.1、并行计算机的分类

+ 并行计算机**能在同一时间内执行多条指令（或处理多个数据）的计算机**

##### 1.1.1、指令与数据

+ MIMD就可以把`A=(B+C)+(D+E)+(F*G)`拆成多个后，然后再加起来

##### 1.1.2、存储方式

+ **共享内存、分布式内存**
  + 分布式内存，靠网络连接起来（**不存在公共可用的存储单元，各个处理器之间通过消息传递来交换信息**）

#### 1.2、物理问题在并行机上的求解

#### 1.3、小结

### chap2、并行编程模型与并行语言（23/348）

#### 2.1、并行编程模型

+ 两种并行编程模型，**数据并行和消息传递**
  + 数据并行，**将相同的操作同时作用于不同的数据**
  + 消息传递，**各个并行执行的部分之间通过传递消息来交换信息、协调步伐、控制执行**，一般是**面向分布式内存**

#### 2.2、并行语言

+ 1、设计全新的
+ 2、扩展原来的串行语言的语法成份
+ 3、**为串行语言提供并行库**，MPI就是这样

chap3、并行算法

chap4、MPI简介

chap5、第一个MPI程序

chap6、六个接口构成的MPI子集

### chap7、简单的MPI程序示例（53/348）

#### 7.1、用MPI实现计时功能

+ *敲了代码*

7.2、获取机器的名字和MPI版本号

7.3、是否初始化及错误退出

7.4、数据接力传送

7.5、任意进程间相互问候

7.6、任意源和任意标识的使用

7.7、编写安全的MPI程序

7.8、小结

### chap8、MPI并行程序的两种基本模式（68/348）

#### 8.1、对等模式的MPI程序设计

##### 8.1.1、问题描述-Jacobi迭代

+ jacobi是，求解线性方程组

#### 8.2、主从模式的MPI程序设计

##### 8.2.1、矩阵向量乘

+ `C=A*B`，
  + 主进程把向量B广播给所有从进程，然后将矩阵A的各行依次发送给从进程
  + 从进程计算一行和B相乘的结果，然后再将结果发送给主进程

##### 8.2.2、主进程打印各从进程的消息

+ *Q，如何解决MPI中存在的死锁*
+ 83/348的例子，还没敲呢

### chap9、不同通信模式MPI并行程序的设计（86/348）

+ 4种
  + 是否需要对发送的数据进行缓存？
  + 是否只有当接收调用执行后才可以执行发送操作？
  + 什么时候发送调用可以正确返回？
  + 发送调用正确返回是否意味着发送已完成？即发送缓冲区是否可以被覆盖？发送数据是否已到达接收缓冲区？

#### 9.1、标准通信模式

#### 9.2、缓存通信模式

+ `MPI_BSEND()`，**对通信缓冲区的合理与正确使用是由程序设计人员自己保证的**

#### 9.3、同步通信模式

+ `MPI_SSEND()`

#### 9.4、就绪通信模式

+ `MPI_RSEND()`

#### 9.5、小结

### chap10、MPICH的安装与MPI程序的运行（97/348）

#### 10.1、Linux环境下的MPICH

#### 10.2、Windows NT环境下的MPICH

### chap11、常见错误（109/348）

### chap12、非阻塞通信MPI程序设计（113/348）

#### 12.1、阻塞通信