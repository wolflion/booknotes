### 缘起

+ 冯唐《成事心法》
  + 100个关键词
  + 3-5个行业专家（见不到本人，就看他的采访，看他的blog，书）
  + 3-5本行业专著

### 100个名词

+ 1、epochs
+ 2、batch-size
+ 3、tensor（张量）
  + 多维数组
  + tensorflow是框架，来自于DistBelief，对应有个论文
+ 4、层（layer）与块（block）
  + 多个层，组成块？
+ 5、并行策略（DP，EP，PP）
+ 6、op_name，算子名称，算子定义
+ 7、training，inference训练和推理
+ 8、hidden layer 隐藏层
  + 切分hidden size，没并行
+ 9、CNN和DNN有啥区别，池化层、全连接层、卷积层
  + *《深度学习轻松学》*没有提交*，【回来发现，都没有写笔记，就在读而已】*
  + CNN是卷积神经网络，**二维数据**，
  + DNN是深度神经网络，**各种数据**，
  + CNN的池化层
    + pooling
    + 减少特征图的大小和参数数量，**跟在卷积层后面**，对卷积后降维
  + 全连接层
    + cnblogs.com/MrSaver，子烁爱学习
    + 也叫**密集连接层**，dense，
    + 前一层的所有神经元将当前层的所有神经元相连接，形成全连接网络结构，每个连接有权重和偏置，**通常在最后一层**，将前面所有特性连接起来
  + 卷积层
    + **卷积核**在输入层滑动，**计算内积**，得到新的特征图，**优点是共享权重**
  + **卷积核**
    + 是**小矩阵**（大小，形状，自己设定），长方形，圆形，方形，**堆叠多个卷积层，池化层**
+ 10、reduce和mapreduce，ring-allreduce
  + reduce怎么理解，**集合中所有元素通过某种操作进行汇总**
  + github.com/baidu_reseach/baidu_allreduce，*想看下mapreduce的论文*
  + ring-reduce，大块分成小块，小块进行reduce操作，然后归总，**放到一个环形结构中**
    + python中mpi库，mpi4py
  + 数据并行（DP）训练的集合通信基础

### ref

+ github.com/dragen1860/TensorFlow2，深度学习开源书

+ 《动手学深度学习》