## 《操作系统导论》

+ Part1、虚拟化
  + 虚拟化CPU（3-11）
  + 虚拟化内存（12-24）
+ PartII：Concurrency并发（25-34）
+ Part3、持久性（35-45）
  + 分布式系统（46-50）

### chap1、关于本书的对话

+ OS是如何工作的
  + 它如何决定接下来哪个程序使用CPU
  + 如何在虚拟内存系统中处理内存使用过载
  + 虚拟机监控器如何工作
  + 如果管理磁盘上的数据
  + 如何构建在部分节点失败时仍能正常工作的分布式系统
+ 学习方法
  + 听课，做笔记，**每个周末阅读笔记**，过一段时间**再复习笔记**，**做作业和项目**

### chap2、操作系统介绍

+ 执行指令（处理器从内存中取fetch一条指令，对其解码decode，然后执行execute），**完成这条指令后**，处理器继续执行下一条指令
+ **虚拟化**：OS将物理资源转为更通用、更强大且易于使用的虚拟形式。

#### 2.1、虚拟化CPU

#### 2.2、虚拟化内存

#### 2.3、并发

+ **Key：如何构建正确的并发程序**

#### 2.4、持久性

#### 2.5、设计目标

+ 1、建立抽象
+ 2、提供高性能
+ 3、在应用程序之间以及在OS和应用程序之间提供保护（protection）

#### 2.6、简单历史

##### 早期操作系统：只是一些库

##### 超越库：保护

##### 多道程序时代

##### 摩登时代

#### 2.7、小结

### chap3、关于虚拟化的对话

+ 把一个CPU虚拟成多个虚拟CPU并分给每一个进程使用，**每个应用都以为自己在独占CPU，但实际上只有一个CPU**

### chap4、抽象：进程

+ **进程，就是运行中的程序**

+ 关键问题：**如何提供有许多CPU的假象？**
  + 时分共享（time sharing）CPU技术
+ **机制**（mechanism）：低级机制，**是一些低级方法或协议，实现了所需的功能**
+ **策略**：智能，**在操作系统内做出某种决定的算法**

#### 4.1、抽象：进程

+ 操作系统为正在运行的程序提供的抽象，就是**所谓的进程（process）**

#### 4.2、进程API

+ 创建
+ 销毁
+ 等待
+ 其他控制
+ 状态

#### 4.3、进程创建：更多细节

+ **程序如何转化为进程，也就是说，OS如何启动并运行一个程序？进程创建实际如何进行？**
  + 第一件事是将代码和所有静态数据加载到内在中，加载到进程的地址空间中
  + 创建和初始化栈以及执行与I/O设置相关的其他工作
  + 启动程序，即main()，跳转到main()例程，OS将CPU的控制权转移到新创建的进程中，从而程序开始执行

#### 4.4、进程状态

+ 运行
+ 就绪
+ 阻塞

#### 4.5、数据结构

+ `struct context{};`
+ `struct proc{};`
+ 进程列表

#### 4.6、小结

+ 实现进程所需的低级机制和以智能方式调度这些进程所需的高级策略

#### 问题

### chap5、插叙：进程API

+ `fork()`和`exec()`一对系统调用，再通过`wait()`等待其创建的子进程执行完成。

+ **Key：如何创建并控制进程**

#### 5.1、fork()系统调用

+ *子进程和父进程执行顺序不确定*，参考一下p1.c

#### 5.2、wait()系统调用

#### 5.3、最后是exec()系统调用

+ **exec()系统调用可以让子进程执行与父进程不同的程序**
+ *Q，fork()与exec()的异同，lionel*

#### 5.4、为什么这样设计API

+ 分享fork()和exec()的做法，**给了shell在fork之后exec之前运行代码的机会**

#### 5.5、其他API

+ `kill()`

#### 5.6、小结

+ 读读APUE

#### 作业（编码）

#### 问题

+ 3、使用fork()编写另一程序。子进程应打印"hello"，父进程应打印"goodbye"。你应该尝试确保子进程始终先打印。你能否不在父进程调用wait()而做到这一点呢？

+ 5、编写一程序，在父进程中使用wait()，等待子进程完成。wait()返回什么? 如果你在子进程中使用wait()会发生什么？
+ 6、编写一程序，创建两个子进程，并使用pipe()系统调用，将一个子进程的标准输出连接到另一个子进程的标准输入。

### chap6、机制：受限直接执行

+ 时分共享（time sharing）CPU，实现虚拟化
+ 挑战
  + 1、性能（如何在不增加系统开销的情况下实现虚拟化？）
  + 2、控制权（如何有效地运行进程，同时保留对CPU的控制？）
+ **key，如何高效、可控地虚拟化CPU**

#### 6.1、基本技巧：受限直接执行

+ 受限直接执行（limited direct execution），只需直接在CPU上运行程序即可

#### 6.2、问题1：受限制的操作

+ 如果进程希望执行某种受限操作（如向磁盘发出I/O请求或获得更多系统资源），该怎么办？
+ **引入新的处理器模式，称为用户模式（user mode）**

#### 6.3、问题2：在进程之间切换

+ **key：如何重获CPU的控制权**

##### 协作方式：等待系统调用

##### 非协作方式：操作系统进行控制

##### 保存和恢复上下文

#### 6.4、担心并发吗

#### 6.5、小结

+ 实现CPU虚拟化的关键底层机制：**受限直接执行**，基本思想是：就让想运行的程序在CPU上运行，但首先确保设置好硬件，以便在没有操作系统帮助的情况下限制进程可以执行的操作
+ **虚拟CPU的基本机制**

### chap7、进程调度：介绍

#### 7.1、工作负载假设

+ 对操作系统中运行的进程做出如下的假设：
  + 1、每一个工作运行相同的时间
  + 2、所有的工作同时到达
  + 3、一旦开始，每个工作保持运行直到完成
  + 4、所有的工作只是用CPU（即它们不执行IO操作）
  + 5、每个工作的运行时间是已知的

#### 7.2、调度指标

+ **周转时间**：任务完成时间-任务到达时间
+ 另一个指标是**公平**

#### 7.3、先进先出（FIFO）

#### 7.4、最短任务优先（SJF）

#### 7.5、最短完成时间优先（STCF）

#### 7.6、新度量指标：响应时间

#### 7.7、轮转

#### 7.8、结合I/O

#### 7.9、无法预知

#### 7.10、小结

+ 运行最短的工作，从而优化周转时间
+ 交替运行所有工作，从而优化响应时间

### chap8、调度：多级反馈队列

+ Multi-level Feedback Queue，MLFQ
+ 多级反馈队列解决两方面的问题：
  + 首先，它要优化周转时间
  + 其次，MLFQ希望给交互用户很好的交互体验
+ **Key：没有完备的知识如何调度？**

#### 8.1、MLFQ：基本规则

+ 规则1：如果A的优先级大于B，运行A（不运行B）
+ 规则2：如果A的优先级等于B，轮转运行A和B

#### 8.2、尝试1：如何改变优先级

+ 规则3：工作进入系统时，放在最高优先级（最上层队列）
+ 规则4a：工作用完整个时间片后，降低其优先级（移入下一个队列）
+ 规则4b：如果工作在其时间片以内主动释放CPU，则优先级不变

##### 实例1：单个长工作

##### 实例2：来了一个短工作

##### 实例3：如果有I/O呢

##### 当前MLFQ的一些问题

#### 8.3、尝试2：提升优先级

+ 规则5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列

#### 8.4、尝试3：更好的计时方式

+ 规则4：一旦工作用完了其在某一层中的时间配额，就降低其优先级（移入低一级队列）

#### 8.5、MLFQ：调优及其他问题

+ 如何配置一个调度程序
  + 配置多少队列？每一层队列的时间片配置多大？为了避免饥饿问题以及进程行为改变，应该多久提升一次进程的优先级？

#### 8.6、MLFQ：小结

+ 规则1、
+ 规则2、
+ 规则3、
+ 规则4、
+ 规则5、

### chap9、调度：比例份额

+ proportional-share，也称**公平份额（fair-share）**
+ 基于一个简单的想法：**调度程序的最终目标，是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间**
+ **Key：如何按比例分配CPU**

#### 9.1、基本概念：彩票数表示份额

#### 9.2、彩票机制

#### 9.3、实现

#### 9.4、一个例子

#### 9.5、如何分配彩票

#### 9.6、为什么不是确定的

#### 9.7、小结

+ 彩票调度：**通过随机值，聪明地做到了按比例分配**
+ 步长调度：**能够确定的获得需要的比例**

### chap10、多处理器调度（高级）

+ multiprocessor scheduling
+ **Key：如何在多处理器上调度工作**

#### 10.1、背景：多处理架构

+ 与单CPU之间的区别，**核心在于对硬件缓存（cache）的使用，以及多处理器之间共享数据的方式**
+ 单CPU系统中，存在多级的硬件缓存（hardware cache）
+ **缓存一致性**（cache coherence）

#### 10.2、别忘了同步

#### 10.3、最后一个问题：缓存亲和度

+ cache affinity，**一个进程在某个CPU上运行时，会在该CPU的缓存中维护许多状态**

#### 10.4、单队列调度

#### 10.5、多队列调度

#### 10.6、Linux多处理器调度

#### 10.7、小结

### chap11、关于CPU虚拟化的总结对话

### chap12、关于内存虚拟化的对话

### chap13、抽象:地址空间

#### 13.1、早期系统

+ 没有抽象

#### 13.2、多道程序和时分共享

+ **分时共享的方法**，让一个进程单独占用全部内存一小段时间，然后停止它，并将它所有状态信息保存在磁盘上

#### 13.3、地址空间

+ address space，**运行的程序看到的系统中的内存**

#### 13.4、目标

+ 一个目标是**透明**，运行的程序不感知
+ 另一个目标是**效率**，尽可能高效，有时不得不依赖硬件
+ 第三个目标是**保护**，不受其他进程影响，操作系统本身也不会受进程影响

#### 13.5、小结

### chap14、插叙：内存操作API

#### 14.1、内存类型

+ 栈内存，由编译器隐式管理
+ 堆内存，程序员显式调用

#### 14.2、malloc()调用

#### 14.3、free()调用

#### 14.4、常见错误

+ 忘记分配内存
+ 没有分配足够的内存
+ 忘记释放内存
+ 在用完之前释放内存
+ 反复释放内存
+ 错误地调用free()
+ 忘记初始化分配的内存
+ 小结
  + 利用`purify`和`valgrind`工具

#### 14.5、底层操作系统支持

+ malloc和free是库调用，不是系统调用，`brk()`或`sbrk()`才是系统调用。
+ `mmap()`调用从操作系统获取内存

#### 14.6、其他调用

+ `calloc()`和`realloc()`

#### 14.7、小结

### chap15、机制：地址转换

#### 0、

#### 15.1、假设

+ 先假设用户的地址空间必须连续地放在物理内存中
+ 假设每个地址空间大小完全一样

#### 15.2、一个例子

+ **理解地址转换需要什么**

#### 15.3、动态（基于硬件）重定位

+ 基址加虚拟地址（可以看作是地址空间的偏移量）的方式，很容易得到物理地址。**虚拟地址“过大”或者为负数时，会导致异常**

#### 15.4、硬件支持：总结

+ 特权模式（privileged mode）也叫**内核模式**
+ 用户模式

#### 15.5、操作系统的问题

#### 15.6、小结

+ **地址转换（address translation），扩展了受限直接访问的概念**
+ 利用地址转换，操作系统可以控制进程的所有内存访问，确保访问在地址空间的界限内
+ **避免内存碎片**，得到了**分段（segmentation）的概念**

### chap16、分段

#### 0、

+ 之前，一直假设把所有进程的地址空间完整地加载到内存中。
+ **怎样支持大地址空间**

#### 16.1、分段：泛化的基址/界限

+ **在典型的地址空间里有3个逻辑不同的段：代码、栈和堆**
+ 分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存

#### 16.2、我们引用哪个段

+ 硬件在地址转换时使用段寄存器。**它如何知道段内的偏移量，以及地址引用了哪个段？**

#### 16.3、栈怎么办

#### 16.4、支持共享

#### 16.5、细粒度与粗粒度的分段

#### 16.6、操作系统支持

+ 分段带来的问题:
  + 第一个是，**操作系统在上下文切换时应该做什么？**各个段寄存器中的内容必须保存和恢复
  + 第二个是，**管理物理内存的空闲空间**

#### 16.7、小结

+ **分段的好处是：代码共享**

### chap17、空闲空间管理

#### 17.1、假设

+ 在堆上管理空闲空间的数据结构通常称为空闲列表（free list）。**该结构包含了管理内存区域中所有空闲块的引用**。

#### 17.2、底层机制

#### 17.3、基本策略

+ 最优匹配（best fit）
+ 最差匹配（worst fit）
+ 首次匹配（first fit）
+ 下次匹配（next fit）
+ 例子

#### 17.4、其他方式

+ 分离空闲列表（segregated list）
  + **如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象**。
+ 伙伴系统
  + 2的整数次幂大小的空闲块
+ 其他想法

#### 17.5、小结

+ 讨论了最基本的内存分配程序形式。

### chap18、分页：介绍

+ 关键问题：**如何通过页来实现虚拟内存**

#### 18.1、一个简单的例子

+ 操作系统通常为每个进程保存一个数据结构，称为**页表**（page table），主要作用是：**为地址空间的每个虚拟页面保存地址转换（address translation），从而让我们知道每个页在物理内存中的位置**。

#### 18.2、页表存在哪里

+ 20位，就需要2的20次方地址转换，**将每个进程的页表存储在内存中**

#### 18.3、列表中究竟有什么

+ 页表是一种数据结构，用于将虚拟地址映射到物理地址。
  + 可以是**线性页表**
  + **PTE（页表项PageTableEntry）**，有效位、保护位、存在位、参考位

#### 18.4、分页：也很慢

#### 18.5、内存追踪

#### 18.6、小结

+ 分页（paging）比起分段有优点，**不会导致外部碎片、非常灵活**
+ 缺点：机器变慢和内存浪费（内存被页表塞满而不是有用的应用程序数据）
+ **要想一个好的分页系统**

#### 作业

#### 问题

### chap19、分页：快速地址转换（TLB）

+ **Key：如何加速地址转换**
+ 要使用分页，就要将内存地址空间分成大量固定大小的单元（页），**并且需要记录这些单元的地址映射信息**（一般存储在内存中），**这样在转换虚拟地址时，分布逻辑上需要额外一次的内存访问**
+ 增加硬件，**地址转换旁路缓冲存储器（translation-lookaside buffer）TLB**，它是频繁发生的虚拟到物理地址转换的硬件缓存（cache），因此，更好的名称应该是**地址转换缓存（address-translation cache）**

#### 19.1、TLB的基本算法

+ 从虚拟地址中提取页号（VPN），检查TLB是否有该VPN的转换映射，有就命中，从TLB中取出页帧号（PFN），与原来虚拟地址中的偏移量组合形成期望的物理地址（PA），并访问内存。

#### 19.2、示例：访问数组

#### 19.3、谁来处理TLB未命中

+ 硬件或软件

#### 19.4、TLB的内容

+ 硬件TLB中的内容，典型的TLB有32项、64项或128项，**并且是全相联的（fully associative）**

#### 19.5、上下文切换时对TLB的处理

#### 19.6、TLB替换策略

+ **缓存策略**（cache replacement）
+ 关键问题：**如何设计TLB替换策略**

#### 19.7、实际系统的TLB表项

### chap20、分页：较小的表

+ 解决分页引入的第二个问题：**页表太大，因而消耗的内存太多**
+ 关键问题：**如何让页表更小？**

#### 20.1、简单的解决方案：更大的页

#### 20.2、混合方法：分页和分段

#### 20.3、多级页表

##### 详细的多级示例

##### 超过两级

##### 地址转换过程：记住TLB

#### 20.4、反向页表

#### 20.5、将页表交换到磁盘

#### 20.6、小结

+ 构建真正的页表，不一定只是线性数组，**而是更复杂的数据结构**。

### chap21、超越物理内存：机制

+ 关键问题：**如何超越物理内存**

#### 21.1、交换空间

#### 21.2、存在位

#### 21.3、页错误

+ **为什么硬件不能处理页错误**

#### 21.4、内存满了怎么办

+ 页交换策略

#### 21.5、页错误处理流程

#### 21.6、交换何时真正发生

+ 为了保证有少量的空闲内存，大多数操作系统会设置高水位线（High Watermark，HW）和低水位线（Low Watermark，LW），来帮助决定何时从内存中清除页。

#### 21.7、小结

+ **存在位**（present bit），告诉我们页是不是在内存中

### chap22、超越物理内存：策略

#### 22.1、缓存管理

#### 22.2、最优替换策略

#### 22.3、简单策略：FIFO

#### 22.4、另一简单策略：随机

#### 22.5、利用历史数据：LRU

#### 22.6、工作负载示例

#### 22.7、实现基于历史信息的算法

+ 关键问题：**如何实现LRU替换策略**

#### 22.8、近似LRU

#### 22.9、考虑脏页

+ **硬件应该包括一个修改位（modified bit）**

#### 22.10、其他虚拟内存策略

#### 22.11、抖动

#### 22.12、小结

### chap23、VAX/VMS虚拟内存系统

#### 23.1、背景

#### 23.2、内存管理硬件

#### 23.3、一个真实的地址空间

+ **为什么空指针访问会导致段错误**，硬件试图在TLB中查找VPN（这里是0），遇到TLB未命中。查询页表，并且发现VPN 0的条目被标记为无效。把控制权交给OS

#### 23.4、页替换

##### 分段FIFO

##### 页聚集

#### 23.5、其他漂亮的虚拟内存技巧

+ VMS有另外两个现在成为标准和技巧：**按需置零和写入时复制**

#### 23.6、小结

### chap24、内存虚拟化总结对话

### chap25、并发的对话

+ 吃一个桃子？

### chap26、并发：简介

#### 26.3、问题的核心：自由安排

#### 26.4、原子性

### chap27、插曲：线程API

#### 27.1、线程创建

#### 27.2、线程完成

+ 如果你想等待线程完成，会发生什么情况？你需要做一些特别的事情来等待完成。

+ `pthread_join(pthread_t, )`
  + 第1个参数，用于指定要等待的线程
  + 第2个参数，指向你希望得到的返回值

#### 27.3、锁

+ 通过**锁来互斥进入临界区**的那些函数

#### 27.4、条件变量

+ **当线程之间必须发生某种信号时，如果一个线程在等待另一个线程继续执行某些操作**，条件变量就很有用。
+ **要使用条件变量，必须另外有一个与此条件相关的锁**。
+ `int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);`**使调用线程进入休眠状态**，因此等待其它线程发出信号，通常当程序中的某些内容发生变化时，现在正在休眠的线程可能会关心它。

#### 27.5、编译和运行

+ 增加`-pthread`标记，例：`gcc -o main main.c -Wall -pthread`

#### 27.6、小结

+ `man -k pthread`
+ **线程难的部分不是API，而是如何构建并发程序的棘手逻辑**。

### chap28、锁

#### 28.1、锁的基本思想

+ 锁为程序员提供了最小程度的调度控制。通过给临界区加锁，可以保证临界区内只有一个线程活跃。**锁将原本由操作系统调度的混乱状态变得更为可控**。

```c++
lock_t mutex;//some globally-allocated lock 'mutex'
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex);
```

#### 28.2、pthread锁

+ POSIX库将锁称为**互斥量（mutex）**，因为它被用来提供线程之间的互斥。即当一个线程在临界区，它能够阻止其他线程进入直到本线程离开临界区。

#### 28.3、实现一个锁

+ 怎样实现一个锁？
+ **我们需要硬件和操作系统的帮助来实现一个可用的锁**。

#### 28.4、评价锁

+ 评价锁是否能工作，应设立一些标准：
  + 1、锁是否能完成它的基本任务，即**提供互斥（mutual exclusion）**，锁是否有效，能够阻止多个线程进入临界区
  + 2、公平性（fairness）：当锁可用时，是否每一个竞争线程有公平的机会抢到锁？
  + 3、性能（performance）：使用锁之后增加的时间开销

#### 28.5、控制中断

+ 临界区关闭中断，为单处理器系统开发，**优点是简单、缺点很多**
  + 1、一个贪婪的程序可能在它开始时就调用lock()，从而独占处理器
  + 2、不支持多处理器
  + 3、关闭中断导致中断丢失，可能会导致严重的系统问题
  + 4、系统低

#### 28.6、测试并设置指令（原子交换）

+ **test and set**
  + 首先实现一个不依赖它的锁，用一个变量标记锁是否被持有

#### 28.7、实现可用的自旋锁

#### 28.8、评价自旋锁

+ 1、正确性（correctness）
+ 2、公平性
+ 3、性能

#### 28.9、比较并交换

+ 比较并交换的思路是：**检测ptr指向的值是否和expected相等**

#### 28.10、链接的加载和条件式存储指令

+ 链接的加载指令
+ **条件式存储（store-conditional）指令**

#### 28.11、获取并增加

+ 硬件原语：**获取并增加（fetch-and-add）指令**

#### 28.12、自旋过多：怎么办

+ **Key：怎样避免自旋**

#### 28.13、简单方法：让出来吧，宝贝

+ 要自旋的时候，放弃CPU，**调用`yield()`**

#### 28.14、使用队列：休眠替代自旋

+ park()能够让调用线程休眠，unpark(threadID)则会唤醒threadID标识的线程

#### 28.15、不同操作系统，不同实现

#### 28.16、两阶段锁

+ 第一阶段会先自旋一段时间，希望它可以获取锁
+ 如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用

#### 28.17、小结

#### 作业

#### 问题

+ 1、
+ 9、现在用不同的-i值运行代码。你看到了什么样的不同行为？

### chap29、基于锁的并发数据结构

+ **Key：如何给数据结构加锁？**

#### 29.1、并发计数器

##### 简单但无法扩展

##### 可扩展的计数

#### 29.2、并发链表

##### 扩展链表

#### 29.3、并发队列

#### 29.4、并发散列表

+ code

```c
#define BUCKETS(101)
typedef struct _hash_t {
    list_t lists[BUCKETS];
}hash_t;

void Hash_Init(hash_t *H) {
    int i;
    for(i=0;i<BUCKETS;i++){
        List_Init(&H->list[i]);
    }
}

int Hash_Insert(hash_t *H, int key) {
    int bucket = key % BUCKETS;
    retun list_Insert(&H->lists[bucket],key);
}

int Hash_Lookup(hash_t *H, int key) {
    int bucket = key % BUCKETS;
    retun list_Lookup(&H->lists[bucket],key);
}
```



#### 29.5、小结

### chap30、条件变量

+ 在很多情况下，线程需要检查某一条件（condition）满足之后，才会继续运行。
+ **父线程需要检查子线程是否执行完毕【这通常称为join()】**
+ **Key：如何等待一个条件？**
+ Code

```c
volatile int done = 0;
void *child(void *arg) {
    printf("child\n");
    done = 1;
    return NULL;
}

int main(int argc, char *argv[]) {
    printf("parent:begin\n");
    pthread_t c;
    Pthread_create(&c, NULL, child, NULL);// create child
    while(done == 0)
        ;//spin
    printf("parent:end\n");
    return 0;
}
```



#### 30.1、定义和程序

+ **条件变量**是个显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等待该条件。
+ **条件变量有两种相关操作**
  + wait()，**线程要睡眠的时候**
  + signal()，**线程想唤醒等待在某个条件变量上的睡眠线程时**

#### 30.2、生产者/消费者（有界缓冲区）问题

##### 有问题的方案

##### 较好但仍有问题的方案：使用while语句

##### 单值缓冲区的生产者/消费者方案

##### 最终的生产者/消费者方案

#### 30.3、覆盖条件

#### 30.4、小结

+ **当某些程序状态不符合要求时，通过允许线程进入休眠状态**，条件变量使我们能够漂亮地解决许多重要的同步问题

### chap31、信号量

+ **Key：如何使用信号量**

#### 31.1、信号量的含义

+ **信号量是有一个整数值的对象，可以用2个函数来操作它**，`sem_wait()`和`sem_post()`

#### 31.2、二值信号量（锁）

+ **用信号量作为锁**

#### 31.3、信号量用作条件变量

#### 31.4、生产者/消费者（有界缓冲区）问题

##### 第一次尝试

##### 解决方案：增加互斥

##### 避免死锁

##### 最后，可行的方案

#### 31.5、读者-写者锁

#### 31.6、哲学家就餐问题

##### 有问题的解决方案

##### 一种方案：破除依赖

#### 31.7、如何实现信号量

#### 31.8、小结

### chap32、常见并发问题

#### 32.1、有哪些类型的缺陷

+ 死锁
+ 非死锁

#### 32.2、非死锁缺陷

##### 违反原子性缺陷

##### 违反顺序缺陷

##### 非死锁缺陷：小结

#### 32.3、死锁缺陷

##### 为什么发生死锁

##### 产生死锁的条件

##### 预防

##### 通过调度避免死锁

##### 检查和恢复

#### 32.4、小结

### chap33、基于事件的并发（进阶）

+ **Key：不用线程，如何构建并发服务器**

#### 33.1、基本想法：事件循环

+ Code

```c
while(1) {
    events = getEvents();
    for (e in events) 
        processEvent(e);
}
```



#### 33.2、重要API：select()（或poll()）

#### 33.3、使用select()

#### 33.4、为何更简单？无须锁

#### 33.5、一个问题：阻塞系统调用

#### 33.6、解决方案：异步I/O

#### 33.7、另一个问题：状态管理

#### 33.8、什么事情仍然很难

### chap34、并发的总结对话

+ 尽可能简单。**避免复杂的线程交互，使用已被证实的线程交互方式**

### chap35、关于持久性的对话

### chap36、I/O设备

+ Key：**如何将I/O集成进计算机系统中**

#### 36.1、系统架构

+ 物理布局及造价成本，**让要求高性能的设备（比如显卡）离CPU更近一些，低性能的设备离CPU远一些**

#### 36.2、标准设备

+ 第一部分是**向系统其他部分展现的硬件接口**
+ 第二部分是**它的内部结构**，这部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口

#### 36.3、标准协议

+ 一个（简化的）设备接口包含3个寄存器
  + 状态寄存器：可以读取并查看设备的当前状态
  + 命令寄存器：用于通知设备执行某个具体任务
  + 数据寄存器：将数据传给设备或从设备接收数据
+ 协议包含4步
  + 第1步
  + 第2步
  + 第3步
  + 第4步

```c++
while(STATUS == BUSY)
    ; //wait until device is not busy
write data to DATA register
write command to COMMAND regiser
    (Doing so starts the device and executes the command)
while(STATUS == BUSY)
    ;//wait until device is done with your request
```

+ Key，**如何减少轮询开销**
  + 利用中断

#### 36.4、利用中断减少CPU开销

+ 高性能场景，不要用中断
+ 最好不要使用中断的场景是**网络**

#### 36.5、利用DMA进行更高效的数据传送

+ Key，**如何减少PIO的开销**
+ DMA引擎是系统中的一个特殊设备，它可以协调完成内存和设备间的数据传递，不需要CPU介入。
+ **DMA工作过程**：
  + 为了能够将数据传送给设备，OS会能过编程告诉DMA引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。
+ **数据的拷贝工作都是由DMA控制器来完成的**。

#### 36.6、设备交互的方法

+ Key，**如何与设备通信**
  + 第1种：**用明确的I/O指令**
  + 第2种：内存映射I/O，**好处是，不需要引入新指令来实现设备交互**

#### 36.7、纳入操作系统：设备驱动程序

+ Key，**如何实现一个设备无关的操作系统**
  + 抽象（abstraction）技术

#### 36.8、案例研究：简单的IDE磁盘驱动程序

#### 36.9、历史记录

+ 在20世纪50年代中期，就有系统的I/O设备可以直接和内存交互，并在完成后中断CPU。

#### 36.10、小结

+ 中断和DMA
+ I/O指令和内存映射I/O

### chap37、磁盘驱动器

#### 37.1、接口

+ 扇区
+ 地址空间，address space

#### 37.2、基本几何形状

#### 37.3、简单的磁盘驱动器

+ 单磁道延迟:旋转延迟
+ 多磁道:寻道时间
+ 一些其他细节

#### 37.4、I/O时间:用数学

#### 37.5、磁盘调度

+ SSTF:最短寻道时间优先
+ 电梯（SCAN或C-SCAN）
+ SPTF:最短定位时间优先
+ 其他调度问题

#### 37.6、小结

### chap38、RAID

#### 38.1、接口和RAID内部

#### 38.2、故障模型

#### 38.3、如何评估RAID

#### 38.4、RAID0级:条带化

#### 38.5、RAID1级:镜像

#### 38.6、RAID4级:通过奇偶校验节省空间

#### 38.7、RAID5级:旋转奇偶校验

#### 38.8、RAID比较:总结

#### 38.9、其他有趣的RAID问题

#### 38.10、小结

+ RAID将大量独立磁盘扩充成更大、更可靠的单一实体。并且是透明的。

### chap39、插叙:文件和目录

### chap40、文件系统实现

#### 40.1、思考方式

+ 第一个方面是，文件系统的数据结构，**哪些类型的结构来组织来数据和元数据**
+ 第二个方面是，访问方法 **如何将进程发出的调用映射到结构上的？在系统调用期间读取哪些数据结构？改写哪些结构？这些步骤的执行效率如何？**

#### 40.2、整体组织

#### 40.3、文件组织:inode

+ 多级索引

#### 40.4、目录组织

+ *书中是简单的线性目录列表，看下真实的文件系统如何的？*

#### 40.5、空闲空间管理

+ 位图

#### 40.6、访问路径:读取和写入

##### 40.6.1、从磁盘读取文件

+ `open("/foo/bar")`，先根目录，再遍历foo目录，最后找到bar的inode号，再读入内存，权限检查后，返回文件描述符。
+ 打开后，再read系统调用，查找块的位置，更新inode的最后访问时间

##### 40.6.2、写入磁盘

+ 5次I/O
  + 读取位图
  + 写入位图
  + 两次读取，写入inode
  + 写入真正的数据块本身

#### 40.7、缓存和缓冲

#### 40.8、小结

### chap41、局部性和快速文件系统

### chap42、崩溃一致性:FSCK和日志

+ crash-consistency problem

#### 42.1、一个详细的例子

#### 42.2、解决方案1:文件系统检查程序

#### 42.3、

#### 42.4、

#### 42.5、小结

### chap43、日志结构文件系统

### chap44、数据完整性和保护

### chap45、关于持久性的总结对话

### chap46、关于分布式的对话

### chap47、分布式系统

### chap48、Sun的网络文件系统（NFS）

### chap49、Andrew文件系统（AFS）

### chap50、关于分布式的总结对话

## 履历

+ 2022年27W（7.5-7.）看Part2并发的chap26，但习题没做和练习，只是有个概念